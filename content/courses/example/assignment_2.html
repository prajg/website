---
title: "Assignment 2"
output:
  pdf_document: default
  word_document: default
date: '2019-10-09'
---



<div id="question-1" class="section level2">
<h2>Question 1</h2>
<p>If we write down the model using the <span class="math inline">\(\hat{\beta}\)</span> coefficients we are provided, we have:</p>
<p><span class="math display">\[ \hat{y} = 50 + 20*GPA + 0.07*IQ + 35*Gender + 0.01*(GPA \times IQ) - 10*(GPA \times Gender)  \]</span><br />
where Gender is 1 for Female and 0 for Male and <span class="math inline">\(\hat{y}\)</span> represents salary in thousands</p>
<p>So, if we write separate models for male and female, we have:</p>
<p>For Male, the model is:</p>
<p><span class="math display">\[ \hat{y} = 50 + 20*GPA + 0.07*IQ + 0.01*(GPA \times IQ)  \]</span> For Female, the model is:</p>
<p><span class="math display">\[ \hat{y} = 85 + 10*GPA + 0.07*IQ + 0.01*(GPA \times IQ)  \]</span></p>
<div id="part-a" class="section level3">
<h3>Part a:</h3>
<p>Here, all the options are comparing Male’s Salary with respect to Female’s.</p>
<p>So, firstly, let’s just equate both the models to see how does the inequality work out. If we want to see when, on average, do female earn more than male, the inequality we have is:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;  85 + 10*GPA + 0.07*IQ + 0.01*(GPA \times IQ) &gt; 50 + 20*GPA + 0.07*IQ + 0.01*(GPA \times IQ) \\
&amp; 85 + 10*GPA &gt; 50 + 20*GPA \\
&amp; 3.5 &gt; GPA
 \end{aligned}
\]</span></p>
<p>Therefore, when the GPA is smaller than 3.5, females, on average, earn more than males.</p>
<p><strong>(i)</strong> is <strong>incorrect</strong> as males, on average, earn more than females only when GPA is greater than 3.5, and not in general for any constant value of GPA.<br />
<strong>(ii)</strong> is <strong>incorrect</strong> as females, on average, earn more than males only when GPA is less than 3.5, and not in general for any constant value of GPA.<br />
<strong>(iii)</strong> is <strong>correct</strong> as males, on average, earn more than females when GPA is greater than 3.5. So, if we quantify high GPA as GPA &gt;3.5, this statement is correct.<br />
<strong>(iv)</strong> is <strong>incorrect</strong> as for high GPA, females earn less than males, on average.</p>
</div>
<div id="part-b" class="section level3">
<h3>Part b:</h3>
<p>Here, we want to predict the salary of a female with IQ 110 and GPA 4.0. So, here, if we plug in the values in our base model, we have:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{Y} &amp;= 85 + 10*GPA + 0.07*IQ + 0.01*(GPA \times IQ) \\
  &amp;= 85 + 10*4 + 0.07*110 + 0.01*(4*110) \\ 
 &amp;= 137.1
 \end{aligned}
\]</span></p>
</div>
<div id="part-c" class="section level3">
<h3>Part c:</h3>
<p>False. To verify if (GPA &amp; IQ) together have an impact, we need to test <span class="math inline">\(H_0: \hat{\beta_4} = 0\)</span> and look at the p-value associated with a t-statistic or an F-statistic to come to a conclusion.</p>
<p>If we notice partial effect of IQ and its interactive term, we see that IQ’s main effect is <span class="math inline">\((0.07*IQ)\)</span> and the effect of interactive term is <span class="math inline">\((0.01*GPA*IQ)\)</span> . So, IQ hierarchical effect is <span class="math inline">\((GPA/7)\)</span> , which is around 57% the above case for GPA = 4.0. So, we can not ignore it before having a closer look at the respective p-value.</p>
</div>
</div>
<div id="question-2" class="section level2">
<h2>Question 2</h2>
<div id="part-a-1" class="section level3">
<h3>Part a:</h3>
<p>By installing the library ISLR, we already have the dataset Carseats. So, we will directly jump to fitting the model.</p>
<pre class="r"><code>mod1 &lt;- lm(Sales ~ Price + Urban + US, data = Carseats)
summary(mod1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sales ~ Price + Urban + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9206 -1.6220 -0.0564  1.5786  7.0581 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.043469   0.651012  20.036  &lt; 2e-16 ***
## Price       -0.054459   0.005242 -10.389  &lt; 2e-16 ***
## UrbanYes    -0.021916   0.271650  -0.081    0.936    
## USYes        1.200573   0.259042   4.635 4.86e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.472 on 396 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2335 
## F-statistic: 41.52 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="part-b-1" class="section level3">
<h3>Part b:</h3>
<p>To interpret the coefficients, we first look at the categorical variables using contrast function</p>
<pre class="r"><code>knitr::kable(contrasts(Carseats$Urban), caption = &quot;Coding R uses in case of Urban vs Rural&quot;)</code></pre>
<table>
<caption><span id="tab:2b">Table 1: </span>Coding R uses in case of Urban vs Rural</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td>Yes</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>knitr::kable(contrasts(Carseats$US), caption = &quot;Coding R uses in case of US vs Non US&quot;)</code></pre>
<table>
<caption><span id="tab:2b">Table 1: </span>Coding R uses in case of US vs Non US</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td>Yes</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Based on the result of contrast function, we observe that person living in urban setting has value 1 for Urban variable and person living in rural setting has value 0 for the same. For US variable, R assigns value 1 if the store is in US and 0 if it is not.</p>
<p>Now that we know the qualitative predictors, we can start interpreting the coefficients in the model.</p>
<ul>
<li>Intercept represents sales(in thousands) for a store where it does not charge any price for car seats, which is in a rural setting and the store is not in US.</li>
<li>For the Price coefficient, we can say that for every unit increase in the price charged for car seats, the sales decrease by approx 54.45 units(0.05445*1000) keeping all other predictors fixed.</li>
<li>Coefficient for UrbanYes indicates the average difference in the sales of a store located in Urban area as compared to rural area. So, if the store is in Urban area, then keeping everything else constant, the sales go down by 21.9 units as compared to stores in Rural area. However, since the p-value is not significant, we can not be certain about this relationship.</li>
<li>Lastly, the USYes coefficient can be interpreted as the average increase in Sales provided that the store is located in the United States. Thus, on average, the sales in a US store are 1200.57 units more than in a non US store keeping all other predictors remaining fixed.</li>
</ul>
</div>
<div id="part-c-1" class="section level3">
<h3>Part c:</h3>
<p><span class="math display">\[ Sales = 13.043469 - 0.054459*Price - 0.021916*UrbanYes + 1.200573*USYes + \epsilon \]</span> where, UrbanYes is 1 if the store is in Urban setting and 0 if not while USYes is 1 if the store is in US and 0 if not</p>
</div>
<div id="part-d" class="section level3">
<h3>Part d:</h3>
<p>For rejecting the null hypothesis <span class="math inline">\(H_0 : \beta_j = 0\)</span>, we would want a small p-value (less than 0.05). So, here we can reject null hypothesis for <strong>Price</strong> and <strong>USYes</strong> variable as their p-value is less than 0.05. A small p-value indicates that we observe an association between the predictor and the response. So, we reject the null hypothesis and declare a relationship to exist between predictor and response.</p>
</div>
<div id="part-e" class="section level3">
<h3>Part e:</h3>
<p>On the basis of previous question, we now want to fit a new smaller model that only uses the predictors for which there is evidence of association with the response.</p>
<pre class="r"><code>mod2 &lt;- lm(Sales ~ Price + US, data = Carseats)
summary(mod2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sales ~ Price + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9269 -1.6286 -0.0574  1.5766  7.0515 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.03079    0.63098  20.652  &lt; 2e-16 ***
## Price       -0.05448    0.00523 -10.416  &lt; 2e-16 ***
## USYes        1.19964    0.25846   4.641 4.71e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.469 on 397 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2354 
## F-statistic: 62.43 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="part-f" class="section level3">
<h3>Part f:</h3>
<p>On comparing the output of summaries, we see that <span class="math inline">\(R^2\)</span> is the same for both the models. So, while going from smaller to bigger model (i.e., model in part (e) to model in part (a)), because the <span class="math inline">\(R^2\)</span> does not increase, we can continue with the smaller model and drop the Price$Urban variable as it is not helping improving the fit.</p>
<p>Moreover, while going from smaller model to base model, RSE increases, F-statistic decreases and the Adjusted <span class="math inline">\(R^2\)</span> decreases a bit as well. So, we can say that smaller model would be marginally better for all the above mentioned reasons and it is also easier to interpret.</p>
<p>But on average, if we just look at the summary statistics for model comparison, the models are quite similar.</p>
</div>
</div>
